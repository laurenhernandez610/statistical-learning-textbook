{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f901cb3",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "\n",
    "Before getting too deep into machine learning lets losely define it. **Definition**: Field of study that gives computers the ability to learn without being explicitly programmed. The more options you give a learning algorithm to learn, the better it will perform. Multiple types of machine learning. \n",
    "\n",
    "* Supervised learning (it has the most real world applications)\n",
    "* Unsupervised learning\n",
    "* Reinforcement learning\n",
    "\n",
    "The algorithms are tools, but you need to know how to **USE** the tools. \n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "This is most popular type of machine learning used is used in the industry and what caused all the hype. Lets define this in a clear way. Supervised learning deals with algorithms that learn **input** $\\to$ **output label** mappings. This means that you give it something (an input) and it will spit out a label that is associated to that input. The main point of supervised learning is that give your algorithm inputs that are correct so that it can learn from them. Eventually the algorithm can be given only the input and gives you the closest prediction to the output that it thinks is correct. A correct answer is the correct label y given x and seeing pairs of x and desired output label y. Supervised learning is giving an algorithm a dataset in which the correct answser, the label, is given. The algorithm is meant to produce more of those right answers but with x's that it has never seen before. If it is still unclear, supervised learning learns from data labeled with the correct answers. \n",
    "\n",
    "### Type of algorithms\n",
    "* Regression\n",
    "    * Predicts numbers from infintely many possible outcomes\n",
    "* Classification\n",
    "    * Predicts categories from a small possible set of outputs\n",
    "    \n",
    "## Unsupervised Learning\n",
    "\n",
    "The second most widely used type of machine learning. Unsupervised learning's job is to find some structure or sort of pattern or just find something interesting in the data. It is called unsupervised because we do not want to supervise the algorithm to give some right answer for every input. Instead the algorithm discoveres something interesting or some sort of structure in the data. We aren't telling the algorithm in advance what the label is, we want the algorithm to do that for us. A formal **definition** would be data that only comes with inputs $x$, but not the output label $y$. The algorithm has to find structure in the data.\n",
    "\n",
    "### Types of algorithms\n",
    "* Clustering\n",
    "   * Takes data without labels and tries to automatically group them into clusters. \n",
    "* Anomaly detection\n",
    "   * Find unusual data points in the data. \n",
    "* Dimentsionality Reduction\n",
    "   * Lets you take a big-data set and compress it into a smaller dataset with losing as little information as possible. \n",
    "\n",
    "# Supervised Learning Algorithms\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "**Regression** models predict numbers. Any model that spits out a number is a regression model. There are different types of regression but for now we will cover linear regression. \n",
    "\n",
    "### Useful terminology\n",
    "The data that is used to train a model is known as the **training set**. The standard notation for the training set inputs is $x$ which is also commonly referred to as the input variable, feature, or input feature. To denote the output variable is $y$ which is also commonly referred to as the output variable or target variable. We will use $m$ to denote the the number of training examples. To denote a single training example you use the format $(x, y)$. One more format that we will use to denote the $i$th training example. If you have 10 examples then using the format $(x^{(i)}, y^{(i)}) \\to (x^{10}, y^{10})$. Remember that your $m$ denotes the amount of examples you have. $i$ will go on until the final $m$, it also refers to a specific row in a table. Make sure to not confuse the the $i$ with an exponent. The $i$ is the row number.  \n",
    "\n",
    "What does a training set hold? \n",
    "1. features\n",
    "2. targets \n",
    "\n",
    "### What is the function?\n",
    "\n",
    "When you train a model you will give it the inputs and desired outputs so that the algorithm can make some sort of model in the form of a function denoted by $f$. You can think of $f$ as a hypothesis. It's job is to take a new input $x$ an estimate or a prediction which is denoted by $\\hat{y}$. Like mentioned earlier the function is just the model. The difference between $y$ and $\\hat{y}$ is that $y$ will refer to the true value. $\\hat{y}$ refers to the estimation that your model made which may or not be the actual true value. The true value will not be known until whatever you are predicting produces that true value. We may represent $f$ with mathematics. Normally it is denoted by $$ f_{w, b} (x) = wx + b$$ which reads out as $f$ is a function that takes $x$ as an input, and depending on the values of $w$ and $b$, our function $f$ will output some estimated value $\\hat{y}$. A lot of the times we can just simplify the notation to $f(x)$ as writing the subscript out everytime can be tedious. Although the functions we work with will always be written with this format as its true form. \n",
    "\n",
    "#### Why do we choose a straight line? \n",
    "\n",
    "It is easy to understand more complex models when you have the idea of linear regression engraved into your brain. Linear regression is a gateway to understanding non-linear datasets. Linear regression with one variable is known as **univariate** linear regression which only takes in one feature $x$. In linear regression you have two parameters $w$ and $b$ which are \"fit\" using training dat to make the best line. Knowing the parameters will allow the model to make future predictions on unseen data. \n",
    "\n",
    "# The Cost Function\n",
    "\n",
    "The **cost function** tells us how well the model is doing so that we can try to get it do perform better. If you recall from our linear function we had $w$ and $b$, formally these are known as the **parameters** of the model and we can adjust these during training in order to improve the model. They are also referred to as **coefficients** or **weights**. Something you are probably wondering now is how can we find these parameters such that our predicted output, $\\hat{y}^{(i)}$, is as close as possible to the target output, $y^{(i)}$, for every single pair, $(x^{(i)}, y^{(i)})$. So what does the cost function really do? This is the formula $$\\frac{1}{m} \\sum_{i = 1}^{m}(\\hat{y}^{(i)} - y^{(i)})^{2}$$ What we are doing here is taking the square error which is the just predicted output minus the target out and squaring it. We do this for all training examples, $m$, where $i$ represents the specific value of $m$ we are currently computing. Then it is averaged of all training examples times 2. The 2 is added because it makes the expression easier later on. To **formally** define this, this is known as the **Squared Error Cost Function** and it is given by the following $$ J(w, b) = \\frac{1}{2m} \\sum_{i = 1}^{m}(f_{w, b}(\\hat{y}^{(i)}) - y^{(i)})^{2}$$ This cost function is widely used in regression problems as it gives very good results. Eventually we want to find a way to minimize these parameters $w$ and $b$. \n",
    "\n",
    "## Understanding the cost function\n",
    "\n",
    "You can ask yourself, what is the point or goal of the cost function? Well the main goal of the cost function is to minimize it as much as possible, which mathematically is denoted as such, $\\min_{w,b} J(w, b)$. You now have four things, your model, the parameters of that model, the cost function that will minimize those parameters, and finally your end goal that is the cost function with ideal parameters. What do we mean by minimizing the cost function though? Well the cost function spits out an error no? We want to minimize that error. How do we do that though? How do we choose the correct values to minimize the cost function? We will discover this in a later section. For now just know that when the cost function, $J$, is at a minimum then the model fits the data relatively well. Plotting may help understand this better. (Possibly do an example in class)\n",
    "\n",
    "### Quick Recap\n",
    "\n",
    "* Model: $f_{w, b} = wx + b$\n",
    "* Parameters: $w, b$\n",
    "* Cost Function: $J(w, b) = \\frac{1}{2m} \\sum_{i = 1}^{m}(f_{w, b}(\\hat{y}^{(i)}) - y^{(i)})^{2}$\n",
    "* Objective: $\\min_{w,b} J(w, b)$\n",
    "\n",
    "Normally you want to get a visual understanding of your function, $f_{w, b}$, and how it relates to the cost function, $J(w, b)$. We will visualize this soon so that you can understand it better. Using contour plots will help us understand cost functions. It will show all points at the same height.\n",
    "## Coding the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f76427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for scientific computing\n",
    "\n",
    "def cost_function(x, y, w, b): # We need our input, output, parameters. These will be fed into the function\n",
    "    \"\"\"\n",
    "    This function will return the total cost of using w and b as our parameters for the model.\n",
    "    \"\"\"\n",
    "    m = x.shape[0] # number of training examples\n",
    "    \n",
    "    cost_sum = 0\n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        sq_error = (f_wb - y[i]) ** 2\n",
    "        cost_sum += sq_error\n",
    "    cost_function =  (1 / 2 * m) * cost_sum\n",
    "    \n",
    "    return cost_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa337385",
   "metadata": {},
   "source": [
    "I hope this code block makes sense. Essentially we broke the cost function into multiple parts that allows us to calculate the total cost easier. We use a for loop here because we calculated the number of training examples we have with $m$. We know how many examples there is going to be, thus a for loop is appropiate. Essentially we are just creating a function that allows the computer to compute the cost function and spit out the number we want. Having to manually do this for every single training example would prove to be rather tedious. Now we can move onto a very important topic, gradient descent\n",
    "\n",
    "# Gradient Descent\n",
    "\n",
    "**Gradient descent** is an algorithm that can minimize $J(w, b)$. Here is the general outline:\n",
    "* Start with some $w, b$ (which you can just start at $w = 0, b = 0$) \n",
    "* You keep changing $w, b$ to reduce the cost function $J$\n",
    "* You do this until you settle at the exact **minimum** or near it\n",
    "\n",
    "There may also be more than one minimum depending on the surface. For linear regression there is a bowl shape because you use the square error cost function. Although if you are using a different function, your surface will no longer look like a bowl shape. This will come up later when we dive into things like neural networks. \n",
    "\n",
    "## The Algorithm\n",
    "\n",
    "The gradient descent algorithm is given by $$w = w - \\alpha \\frac{d}{dw} J(w, b)$$ This is saying that you should update your parameter $w$ by taking taking the currently value of $w$ and adjusting it a small amount using the equation given. In this context I will make it that the equals sign is meant to assign an updated value to the variable instead of asserting the truth equality of two variables. In this equation something new you see is $\\alpha$ which is known as the **learning rate**. The learning rate controls how big of step you take downhill. Usually it is between $0 \\to 1$. If it is small then you take small steps, and if it large it takes big steps. The derivative term of the cost function is the last thing. It is telling you in which direction you want to take your new step. Thus together the learning rate and derivative determine the direction and size the algorithm should move. If you are wondering why we are only worried about $w$, then I should clear your worries. You apply the same process to $b$ until you reach **convergence**. $$b = b - \\alpha \\frac{d}{db} J(w, b)$$ You want to update **both** parameters simultaneously. This can be done by computing the right side of the equations and assigning it to the new algorithms. The reason the derivative term is so important is because it always works in a way that will lead you to the minimum. Regardless if your slope is positive or negative the algorithm works in a way that each time the parameter is updated, it is one step closer to the minimum. \n",
    "\n",
    "### What is the learning rate? \n",
    "\n",
    "The **learning rate**, $\\alpha$ \n",
    "* If it is too small $\\implies$ may be slow as it will take many tiny baby steps\n",
    "* If it is too large $\\implies$ may skip over the minimum as it is taking giant steps. It also may fail to converge, or it might even diverge\n",
    "\n",
    "What do you think would happen if you are already at a local minimum and you take another step of gradient descent? If you take a tangent line at that minimum, the slope of it will equal 0. If you can see where this is going then the equation ends up being $w = w - \\alpha \\cdot 0$ which will just return the same value of $w$. \n",
    "\n",
    "# Bringing Gradient Descent and Linear Regression together\n",
    "\n",
    "We are gonna start with deriving the cost function for $w$\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\frac{\\partial}{\\partial w} J(w, b) \n",
    "&= \\frac{\\partial}{\\partial w}\\frac{1}{2m} \\sum_{i = 1}^{m} (f_{w,b} (x^{(i)}) - y^{(i)})^{2} \\\\ \n",
    "&= \\frac{\\partial}{\\partial w}\\frac{1}{2m} \\sum_{i = 1}^{m} (wx^{(i)} + b - y^{(i)})^{2} \\\\ \n",
    "&= \\frac{1}{2m} \\sum_{i = 1}^{m} (wx^{(i)} + b - y^{(i)})2x^{(i)} \\\\ \n",
    "&= \\boxed{\\frac{1}{m} \\sum_{i = 1}^{m} (f_{w,b}(x^{(i)} - y^{(i)})x^{(i)}}\n",
    "\\end{align*}$$\n",
    "\n",
    "The process for $b$ is very similar\n",
    "\n",
    "$$\\begin{align*} \n",
    "\\frac{\\partial}{\\partial b} J(w, b) \n",
    "&= \\frac{\\partial}{\\partial b}\\frac{1}{2m} \\sum_{i = 1}^{m} (f_{w,b} (x^{(i)}) - y^{(i)})^{2} \\\\ \n",
    "&= \\frac{\\partial}{\\partial b}\\frac{1}{2m} \\sum_{i = 1}^{m} (wx^{(i)} + b - y^{(i)})^{2} \\\\ \n",
    "&= \\frac{1}{2m} \\sum_{i = 1}^{m} (wx^{(i)} + b - y^{(i)})2 \\\\ \n",
    "&= \\boxed{\\frac{1}{m} \\sum_{i = 1}^{m} (f_{w,b}(x^{(i)} - y^{(i)})}\n",
    "\\end{align*}$$\n",
    "\n",
    "Now that you have those twp expressions they can be plugged in to the gradient descent algorithm. Remember that for linear regression we will only have one global minimum because the square error cost function is a **convex** function. To put it easily, a convex function can only have one global minimum, so it usually looks like a bowl. Thus, when you implement gradient descent into a convex function, it will always converge to the global minimum given that your learning rate is appropriate. **Batch** gradient descent is a type of gradient descent. Batch refers to the fact that each step of gradient descent uses **all** the training examples. There are other types of gradient descent which use subsets of data. Although for linear regression we use batch gradient descent. \n",
    "\n",
    "# Coding Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719ac35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b):\n",
    "    \"\"\"\n",
    "    This will compute the gradient for linear regression\n",
    "    It will return dw and db\n",
    "    \"\"\"\n",
    "    m = x.shape[0]\n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        dj_dw_i = (f_wb - y[i]) * x[i]\n",
    "        dj_db_i = (f_wb - y[i])\n",
    "        dj_dw += dj_dw_i\n",
    "        dj_db += dj_db_i\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    return dj_dw, dj_db\n",
    "\n",
    "def gradient_descent(x, y, w_in, b_in, num_iters, cost_function, gradient_function):\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    w = w_in\n",
    "    dj_dw, dj_db = gradient_function(x, y, w, b)\n",
    "    \n",
    "    b = b - alpha * dj_db\n",
    "    w = w - alpha * dj_db\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9394a867",
   "metadata": {},
   "source": [
    "This is the code block on you would implement gradient descent. I hope it is clear how it is implemented as most of the work is putting the formulas into code that the computer can understand. With that being said, this concludes the first module of machine learning. We learned about the different types of machine learning, linear regression, and a very common algorithm, gradient descent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
